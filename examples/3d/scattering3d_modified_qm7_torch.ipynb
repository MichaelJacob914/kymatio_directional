{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8010bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn import (linear_model, model_selection, preprocessing,\n",
    "                     pipeline)\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from kymatio.torch import HarmonicScattering3D\n",
    "\n",
    "from kymatio.scattering3d.backend.torch_backend \\\n",
    "    import TorchBackend3D\n",
    "\n",
    "from kymatio.scattering3d.utils \\\n",
    "    import generate_weighted_sum_of_gaussians\n",
    "\n",
    "from kymatio.datasets import fetch_qm7\n",
    "from kymatio.caching import get_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b3dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qm7_url = \"https://qmml.org/Datasets/gdb7-12.zip\"\n",
    "def fetch_qm7(align=True, cache=True):\n",
    "    \"\"\"Fetches the GDB7-12 dataset\"\"\"\n",
    "\n",
    "    cache_path = get_cache_dir(\"qm7\")\n",
    "    if cache:\n",
    "        cache_path = get_cache_dir(\"qm7\")\n",
    "        if align:\n",
    "            aligned_filename = os.path.join(cache_path, \"qm7_aligned.npz\")\n",
    "            if os.path.exists(aligned_filename):\n",
    "                f = np.load(aligned_filename)\n",
    "                return dict(**f)\n",
    "\n",
    "        # load unaligned if existent, align if required\n",
    "        unaligned_filename = os.path.join(cache_path, \"qm7.npz\")\n",
    "        if os.path.exists(unaligned_filename):\n",
    "            f = np.load(unaligned_filename)\n",
    "            if align:\n",
    "                _pca_align_positions(f['positions'], f['charges'], inplace=True)\n",
    "                np.savez(aligned_filename, **f)\n",
    "            return dict(**f)\n",
    "\n",
    "    path = get_cache_dir(\"qm7\")\n",
    "    qm7_file = os.path.join(path, \"gdb7-12/dsgdb7ae.xyz\")\n",
    "    if not os.path.exists(qm7_file):\n",
    "        qm7_zipfile = os.path.join(path, \"gdb7-12.zip\")\n",
    "        if not os.path.exists(qm7_zipfile):\n",
    "            _download(qm7_url, qm7_zipfile)\n",
    "            import zipfile\n",
    "            with zipfile.ZipFile(qm7_zipfile, \"r\") as zipref:\n",
    "                zipref.extractall(path)\n",
    "\n",
    "    qm7 = read_xyz(qm7_file)\n",
    "    if cache:\n",
    "        np.savez(unaligned_filename, **qm7)\n",
    "\n",
    "    if align:\n",
    "        _pca_align_positions(qm7['positions'], qm7['charges'], inplace=True)\n",
    "        if cache:\n",
    "            np.savez(aligned_filename, **qm7)\n",
    "\n",
    "    return qm7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing code to fetch in smaller set\n",
    "\n",
    "qm7 = fetch_qm7(align=True, cache = True)\n",
    "pos_full = qm7['positions']\n",
    "full_charges_complete = qm7['charges']\n",
    "\n",
    "cache_path = get_cache_dir(\"qm7\")\n",
    "with open(cache_path + '/gdb7-12/dsgdb7ae_subset1k.txt', 'r') as file:\n",
    "    # Create an empty list to store the lines\n",
    "    lines = []\n",
    "\n",
    "    # Iterate over the lines of the file\n",
    "    for line in file:\n",
    "        # Remove the newline character at the end of the line\n",
    "        line = line.strip()\n",
    "\n",
    "        # Append the line to the list\n",
    "        lines.append(line)\n",
    "        \n",
    "#Take single string stored in above list and convert it into string of indexes\n",
    "string_indexes = lines[0].split(',')\n",
    "indexes = [len(string_indexes)]\n",
    "\n",
    "#convert string indexes to int indexes\n",
    "\n",
    "for i in string_indexes:\n",
    "    int_ver = int(i.strip())\n",
    "    if int_ver in indexes:\n",
    "        continue\n",
    "    indexes.append(int_ver)\n",
    "\n",
    "length = len(indexes)\n",
    "\n",
    "#create pos and full_charges as np arrays with length fitted to dataset \n",
    "pos = np.empty([length, 23, 3])\n",
    "full_charges = np.empty([length, 23])\n",
    "\n",
    "#fill pos and full_charges with data\n",
    "j = 0 #iterator\n",
    "for i in indexes:\n",
    "    pos[j] = pos_full[i]\n",
    "    full_charges[j] = full_charges_complete[j]\n",
    "    j = j + 1\n",
    "\n",
    "n_molecules = pos.shape[0]\n",
    "print(n_molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d800b-a9d2-472a-a34e-de7c147a8cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting here working over 1k subset data set and going to try full code but with the torch.cat implemented\n",
    "# Additional time output added\n",
    "mask = full_charges <= 2\n",
    "valence_charges = full_charges * mask\n",
    "\n",
    "mask = np.logical_and(full_charges > 2, full_charges <= 10)\n",
    "valence_charges += (full_charges - 2) * mask\n",
    "\n",
    "mask = np.logical_and(full_charges > 10, full_charges <= 18)\n",
    "valence_charges += (full_charges - 10) * mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3e240-fbc5-449c-897d-3f60f5dcf53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "overlapping_precision = 1e-1\n",
    "sigma = 2.0\n",
    "min_dist = np.inf\n",
    "\n",
    "for i in range(n_molecules):\n",
    "    n_atoms = np.sum(full_charges[i] != 0)\n",
    "    pos_i = pos[i, :n_atoms, :]\n",
    "    check = min(min_dist, pdist(pos_i).min())\n",
    "    #prevents min_dist from equaling 0 which results in pos being filled with 0 and NaN for data entries\n",
    "    if(check != 0):\n",
    "        min_dist = check\n",
    "    \n",
    "delta = sigma * np.sqrt(-8 * np.log(overlapping_precision))\n",
    "pos = pos * delta / min_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656ec9e-37fe-4076-ac43-bb4d5101e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N, O = 192, 128, 96\n",
    "\n",
    "grid = np.mgrid[-M//2:-M//2+M, -N//2:-N//2+N, -O//2:-O//2+O]\n",
    "grid = np.fft.ifftshift(grid)\n",
    "\n",
    "J = 2\n",
    "L = 3\n",
    "integral_powers = [0.5, 1.0, 2.0, 3.0]\n",
    "\n",
    "scattering = HarmonicScattering3D(J=J, shape=(M, N, O),\n",
    "                                  L=L, sigma_0=sigma,\n",
    "                                  integral_powers=integral_powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dad505-4517-4393-b092-c0e554446dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "scattering.to(device)\n",
    "\n",
    "batch_size = 8\n",
    "n_batches = int(np.ceil(n_molecules / batch_size))\n",
    "\n",
    "order_0, orders_1_and_2 = [], []\n",
    "print('Computing solid harmonic scattering coefficients of '\n",
    "      '{} molecules from the QM7 database on {}'.format(\n",
    "        n_molecules,   \"GPU\" if use_cuda else \"CPU\"))\n",
    "print('sigma: {}, L: {}, J: {}, integral powers: {}'.format(\n",
    "        sigma, L, J, integral_powers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d9d5f-1358-4b0d-99c0-e227b07db2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "this_time = None\n",
    "last_time = None\n",
    "\n",
    "#Run regression for first two intervals to catch errors in appending/functions \n",
    "#before running entire transform across all batches\n",
    "\n",
    "for i in range(2):\n",
    "    this_time = time.time()\n",
    "    if last_time is not None:\n",
    "        dt = this_time - last_time\n",
    "        print(\"Iteration {} ETA: [{:02}:{:02}:{:02}]\".format(\n",
    "                    i + 1, int(((n_batches - i - 1) * dt) // 3600),\n",
    "                    int((((n_batches - i - 1) * dt) // 60) % 60),\n",
    "                    int(((n_batches - i - 1) * dt) % 60)))\n",
    "    else:\n",
    "        print(\"Iteration {} ETA: {}\".format(i + 1, '-'))\n",
    "    last_time = this_time\n",
    "    time.sleep(1)\n",
    "    \n",
    "    t_0 = time.time()\n",
    "\n",
    "    # Extract the current batch.\n",
    "    start = i * batch_size\n",
    "    end = min(start + batch_size, n_molecules)\n",
    "\n",
    "    pos_batch = pos[start:end]\n",
    "    full_batch = full_charges[start:end]\n",
    "    val_batch = valence_charges[start:end]\n",
    "\n",
    "    # Calculate the density map for the nuclear charges and transfer\n",
    "    # to PyTorch.\n",
    "    full_density_batch = generate_weighted_sum_of_gaussians(grid,\n",
    "            pos_batch, full_batch, sigma)\n",
    "    full_density_batch = torch.from_numpy(full_density_batch)\n",
    "    full_density_batch = full_density_batch.to(device).float()\n",
    "\n",
    "    # Compute zeroth-order, first-order, and second-order scattering\n",
    "    # coefficients of the nuclear charges.\n",
    "    full_order_0 = TorchBackend3D.compute_integrals(full_density_batch,\n",
    "                                     integral_powers)\n",
    "    full_scattering = scattering(full_density_batch)\n",
    "\n",
    "    # Compute the map for valence charges.\n",
    "    val_density_batch = generate_weighted_sum_of_gaussians(grid,\n",
    "            pos_batch, val_batch, sigma)\n",
    "    val_density_batch = torch.from_numpy(val_density_batch)\n",
    "    val_density_batch = val_density_batch.to(device).float()\n",
    "\n",
    "    # Compute scattering coefficients for the valence charges.\n",
    "    val_order_0 = TorchBackend3D.compute_integrals(val_density_batch,\n",
    "                                    integral_powers)\n",
    "    val_scattering = scattering(val_density_batch)\n",
    "\n",
    "    # Take the difference between nuclear and valence charges, then\n",
    "    # compute the corresponding scattering coefficients.\n",
    "    core_density_batch = full_density_batch - val_density_batch\n",
    "\n",
    "    core_order_0 = TorchBackend3D.compute_integrals(core_density_batch,\n",
    "                                     integral_powers)\n",
    "    core_scattering = scattering(core_density_batch)\n",
    "\n",
    "    # Stack the nuclear, valence, and core coefficients into arrays\n",
    "    # and append them to the output.\n",
    "    batch_order_0 = torch.stack(\n",
    "        (full_order_0, val_order_0, core_order_0), dim=-1)\n",
    "    batch_orders_1_and_2 = torch.stack(\n",
    "        (full_scattering, val_scattering, core_scattering), dim=-1)\n",
    "\n",
    "    \n",
    "    order_0 = torch.Tensor(order_0)\n",
    "    print(type(order_0))\n",
    "    order_0 = torch.cat((order_0, batch_order_0), 0)\n",
    "\n",
    "    orders_1_and_2 = torch.Tensor(orders_1_and_2)\n",
    "    orders_1_and_2 = torch.cat((orders_1_and_2, batch_orders_1_and_2), 0)\n",
    "    # Changing to utilize torch cat instead of append since error thrown from append\n",
    "    \n",
    "    t_f = time.time()\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (t_f - t_0))\n",
    "    print(\"order 0 size is\", order_0.size(), \"orders 1 and 2 size is\", orders_1_and_2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beecbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform rest of batches\n",
    "for i in range(2, n_batches):\n",
    "    this_time = time.time()\n",
    "    if last_time is not None:\n",
    "        dt = this_time - last_time\n",
    "        print(\"Iteration {} ETA: [{:02}:{:02}:{:02}]\".format(\n",
    "                    i + 1, int(((n_batches - i - 1) * dt) // 3600),\n",
    "                    int((((n_batches - i - 1) * dt) // 60) % 60),\n",
    "                    int(((n_batches - i - 1) * dt) % 60)))\n",
    "    else:\n",
    "        print(\"Iteration {} ETA: {}\".format(i + 1, '-'))\n",
    "    last_time = this_time\n",
    "    time.sleep(1)\n",
    "    \n",
    "    t_0 = time.time()\n",
    "\n",
    "    # Extract the current batch.\n",
    "    start = i * batch_size\n",
    "    end = min(start + batch_size, n_molecules)\n",
    "\n",
    "    pos_batch = pos[start:end]\n",
    "    full_batch = full_charges[start:end]\n",
    "    val_batch = valence_charges[start:end]\n",
    "\n",
    "    # Calculate the density map for the nuclear charges and transfer\n",
    "    # to PyTorch.\n",
    "    full_density_batch = generate_weighted_sum_of_gaussians(grid,\n",
    "            pos_batch, full_batch, sigma)\n",
    "    full_density_batch = torch.from_numpy(full_density_batch)\n",
    "    full_density_batch = full_density_batch.to(device).float()\n",
    "\n",
    "    # Compute zeroth-order, first-order, and second-order scattering\n",
    "    # coefficients of the nuclear charges.\n",
    "    full_order_0 = TorchBackend3D.compute_integrals(full_density_batch,\n",
    "                                     integral_powers)\n",
    "    full_scattering = scattering(full_density_batch)\n",
    "\n",
    "    # Compute the map for valence charges.\n",
    "    val_density_batch = generate_weighted_sum_of_gaussians(grid,\n",
    "            pos_batch, val_batch, sigma)\n",
    "    val_density_batch = torch.from_numpy(val_density_batch)\n",
    "    val_density_batch = val_density_batch.to(device).float()\n",
    "\n",
    "    # Compute scattering coefficients for the valence charges.\n",
    "    val_order_0 = TorchBackend3D.compute_integrals(val_density_batch,\n",
    "                                    integral_powers)\n",
    "    val_scattering = scattering(val_density_batch)\n",
    "\n",
    "    # Take the difference between nuclear and valence charges, then\n",
    "    # compute the corresponding scattering coefficients.\n",
    "    core_density_batch = full_density_batch - val_density_batch\n",
    "\n",
    "    core_order_0 = TorchBackend3D.compute_integrals(core_density_batch,\n",
    "                                     integral_powers)\n",
    "    core_scattering = scattering(core_density_batch)\n",
    "\n",
    "    # Stack the nuclear, valence, and core coefficients into arrays\n",
    "    # and append them to the output.\n",
    "    batch_order_0 = torch.stack(\n",
    "        (full_order_0, val_order_0, core_order_0), dim=-1)\n",
    "    batch_orders_1_and_2 = torch.stack(\n",
    "        (full_scattering, val_scattering, core_scattering), dim=-1)\n",
    "\n",
    "    \n",
    "    order_0 = torch.Tensor(order_0)\n",
    "    order_0 = torch.cat((order_0, batch_order_0), 0)\n",
    "\n",
    "    orders_1_and_2 = torch.Tensor(orders_1_and_2)\n",
    "    orders_1_and_2 = torch.cat((orders_1_and_2, batch_orders_1_and_2), 0)\n",
    "    # Changing to utilize torch cat instead of append since error thrown from append\n",
    "    \n",
    "    t_f = time.time()\n",
    "    \n",
    "    print(\"--- %s seconds ---\" % (t_f - t_0))\n",
    "    print(\"order 0 size is\", order_0.size(), \"orders 1 and 2 size is\", orders_1_and_2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0595d89-49c0-478b-b9d4-fea972b17a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(order_0, \"order_coefficients.csv\")\n",
    "torch.save(orders_1_and_2, \"orders_1_and_2_coefficients.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: NEED TO EDIT TO FIT SUBSET AFTER ABOVE CODE SUCCEDES\n",
    "\n",
    "#commented out code which alters the space in which the arrays are stored\n",
    "#order_0 = torch.cat(order_0, dim=0)\n",
    "#orders_1_and_2 = torch.cat(orders_1_and_2, dim=0)\n",
    "\n",
    "#order_0 = (order_0).cpu().numpy()\n",
    "#orders_1_and_2 = orders_1_and_2.cpu().numpy()\n",
    "\n",
    "order_0 = order_0.reshape((n_molecules, -1))\n",
    "\n",
    "orders_1_and_2 = orders_1_and_2.reshape((n_molecules, -1))\n",
    "\n",
    "basename = 'qm7_L_{}_J_{}_sigma_{}_MNO_{}_powers_{}.npy'.format(\n",
    "        L, J, sigma, (M, N, O), integral_powers)\n",
    "\n",
    "cache_dir = get_cache_dir(\"qm7/experiments\")\n",
    "\n",
    "filename = os.path.join(cache_dir, 'order_0_' + basename)\n",
    "np.save(filename, order_0)\n",
    "\n",
    "filename = os.path.join(cache_dir, 'orders_1_and_2' + basename)\n",
    "np.save(filename, orders_1_and_2)\n",
    "\n",
    "scattering_coef = np.concatenate([order_0, orders_1_and_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc9169-bd70-49ea-8d76-c5f1d4d17f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(scattering_coef, \"scattering_coefficients.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9654035-1af0-4ff8-af39-0c4568e9dea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qm7 = fetch_qm7()\n",
    "target_full = qm7['energies']\n",
    "\n",
    "#takes relevant indexes for energy levels\n",
    "j = 0 #iterator\n",
    "target = np.empty([length])\n",
    "for i in indexes:\n",
    "    target[j] = target_full[i]\n",
    "    j = j + 1\n",
    "\n",
    "#Number of molecules must be divisible by number of folds\n",
    "n_folds = 5\n",
    "\n",
    "P = np.random.permutation(n_molecules).reshape((n_folds, -1))\n",
    "\n",
    "cross_val_folds = []\n",
    "\n",
    "for i_fold in range(n_folds):\n",
    "    fold = (np.concatenate(P[np.arange(n_folds) != i_fold], axis=0),\n",
    "            P[i_fold])\n",
    "    cross_val_folds.append(fold)\n",
    "    \n",
    "#removes NaN data for large datasets and replaces with 0 to preserve eneregy\n",
    "scattering_coef[np.isnan(scattering_coef)] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dba7b4-0bb3-474a-a47a-5114332addc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80eb36-6feb-4a71-a156-05ceb7b73c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10.0 ** (-np.arange(1, 10))\n",
    "for i, alpha in enumerate(alphas):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    ridge = linear_model.Ridge(alpha=alpha)\n",
    "    \n",
    "    \n",
    "    regressor = pipeline.make_pipeline(scaler, ridge)\n",
    "    \n",
    "    target_prediction = model_selection.cross_val_predict(regressor,\n",
    "            X=scattering_coef, y=target, cv=cross_val_folds)\n",
    "\n",
    "    target_prediction2 = model_selection.cross_val_predict(regressor,\n",
    "            X=(target.reshape(-1, 1)), y=target, cv=cross_val_folds)\n",
    "    #prints MAE, RMSE\n",
    "    #expected MAE to be <3.5 kcal/mol\n",
    "    MAE = np.mean(np.abs(target_prediction - target))\n",
    "    RMSE = np.sqrt(np.mean((target_prediction - target) ** 2))\n",
    "\n",
    "    print('Ridge regression, alpha: {}, MAE: {}, RMSE: {}'.format(\n",
    "        alpha, MAE, RMSE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f463d-a29a-451b-9c09-ab0f60afdf5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
